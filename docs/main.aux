\relax 
\citation{bibid}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{2}{}\protected@file@percent }
\citation{Du2011OpenCLCUDA}
\citation{Fang2011CUDAOpenCL}
\citation{Du2011OpenCLCUDA}
\citation{https://arxiv.org/abs/1005.2581}
\citation{}
\citation{https://www.sciencedirect.com/science/article/abs/pii/S0167819111001335}
\citation{https://ieeexplore.ieee.org/document/6047190}
\citation{https://arxiv.org/abs/1005.2581}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{3}{}\protected@file@percent }
\citation{opencl-programming-guide}
\citation{opencl-programming-guide}
\citation{opencl-programming-guide}
\citation{opencl-programming-guide}
\citation{programming-massively-parallel-processors}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The interaction with the host and OpenCL devices which are possible GPUs is displayed here. In a GPU and CPU setup the Host is considered to be the CPU. \cite  {opencl-programming-guide}}}{4}{}\protected@file@percent }
\newlabel{index-space}{{1}{4}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Conecptual differences between OpenCL and CUDA}{4}{}\protected@file@percent }
\citation{opencl-programming-guide}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The work-item resides in an $N \times N$ index-space. Where the shades box is one workitem at location $(6, 5)$ inside the work-group $(1,1)$. Overall the size of the NDRange index space is $12$ divided in $3$ work-groups. While each work-group has $4$ work-items. \cite  {opencl-programming-guide}}}{5}{}\protected@file@percent }
\newlabel{index-space}{{2}{5}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A multidimensional illustration of CUDA grid organization \cite  {opencl-programming-guide}}}{5}{}\protected@file@percent }
\newlabel{index-space}{{3}{5}{}{}{}}
\citation{cuda-programming-guide}
\citation{opencl-programming-guide}
\citation{opencl-programming-guide}
\citation{openCL-programming-guide}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The given image presents all of the architecture parts of the OpenCL framework with considration of the memory model presented. \cite  {opencl-programming-guide}}}{6}{}\protected@file@percent }
\newlabel{index-space}{{4}{6}{}{}{}}
\citation{programming-massively-parallel-processors}
\citation{https://docs.nvidia.com/cuda/parallel-thread-execution/}
\citation{}
\citation{https://www.khronos.org/opencl/?utm_source=chatgpt.com}
\citation{https://registry.khronos.org/OpenCL/specs/3.0-unified/html/OpenCL_API.html?utm_source=chatgpt.com}
\@writefile{toc}{\contentsline {section}{\numberline {IV}The Implementation of the optimizers}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Performance Benchmarks}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VII}References}{7}{}\protected@file@percent }
\gdef \@abspage@last{7}
